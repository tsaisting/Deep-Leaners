---
title: "IMDB Feature Film Analysis"
author: "T2 Deep Learners"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
 knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 

library(tidyr)
library(dplyr)
library(ggplot2)
library(reshape2)

```
### Data cleaning and Merging
```{r data_join}
movies <- read.csv('movies.csv', header=TRUE)
drop <- c('budget','usa_gross_income','worlwide_gross_income','metascore','reviews_from_users',
          'reviews_from_critics','production_company','description','writer')
movies <- movies[,!names(movies) %in% drop]
movies <- movies[!(movies$country == "") & !(movies$language == "") & !(movies$director == "") & !(movies$actors == ""),]
movies
ratings <- read.csv('ratings.csv', header=TRUE)
drop <- c('allgenders_0age_avg_vote', 'allgenders_0age_votes', 'males_0age_avg_vote', 'males_0age_votes',
          'females_0age_avg_vote', 'females_0age_votes', 'us_voters_rating', 'us_voters_votes', 
          'non_us_voters_rating', 'non_us_voters_votes')
ratings <- ratings[,!names(ratings) %in% drop]
ratings <- na.omit(ratings)
ratings
movie_ratings <- merge(movies, ratings, by="imdb_title_id" )

```
### EDA

```{r decription of the data}
library(dplyr)
library(ggplot2)
# average vote distribution
summary(movies$avg_vote)
movies<-movies[!movies$year=='TV Movie 2019',]
hist(movies$avg_vote)
# A brief overview of the dataset: the minimum vote is 1.000,while the maximum vote is 9.900.
# the mean of the vote is 5.902, the median is 6.100.


# movies year-numbers distribution
years_numbers <- movies[,c('imdb_title_id', 'year')]
years_num <- years_numbers %>% count(movies$year)
colnames(years_num)<-c('Year','Movie_numbers')
df1 <-arrange(years_num, -Movie_numbers)
head(df1)
tail(df1)


ggplot(years_num,aes(x=Year,y=Movie_numbers))+geom_col(stat='identity',fill='#f68060',alpha=.6, width=1)+labs(title=('year and Movie_numbers'))+coord_flip()+ylab('Year') + scale_x_discrete(guide = guide_axis(n.dodge=3))



# movies year-rating distribution
years_rating <- aggregate(movies$avg_vote, by = list(director = movies$year),FUN=mean)
colnames(years_rating) <- c('Year','Rating')
df2 <-arrange(years_rating, -Rating)
head(df2)
tail(df2)


ggplot(data=years_rating,aes(x=Year,y=Rating)) +geom_col(width=1,fill='lightblue')+coord_flip()+xlab('Year')+labs(title=('years and Rating'))+ scale_x_discrete(guide = guide_axis(n.dodge=3))

# movies vote distribution
years_vote <- aggregate(movies$votes, by = list(director = movies$year),FUN=sum)
colnames(years_vote) <- c('Year','Votes')
df3 <-arrange(years_vote, -Votes)
head(df3)
tail(df3)


ggplot(data=years_vote,aes(x=Year,y=Votes)) +geom_col(fill='purple4',alpha=1, width=1)+xlab('Year')+ylab('Votes')+coord_flip()+labs(title=('Year and votes'))+ scale_x_discrete(guide = guide_axis(n.dodge=3))

# movies duration-year distribution
years_duration <- aggregate(movies$duration, by = list(director = movies$year),FUN=mean)
colnames(years_duration) <- c('Year','Duration')
df4 <-arrange(years_duration, -Duration)
head(df4)
tail(df4)

ggplot(data=years_duration,aes(x=Year,y=Duration)) +geom_col(fill='purple4',alpha=1, width=1)+xlab('Year')+ylab('Duration')+coord_flip()+labs(title=('Year and Duration'))+ scale_x_discrete(guide = guide_axis(n.dodge=3))
```

```{r}
# loadPkg(pastecs)
# stat.desc(hittersC)
# unloadPkg(pastecs)
```

### Exhaustive search  - Linear Model

Q: How is the salary is effected by other variables in the dataset?
```{r results='markup'}
loadPkg("leaps")
#This is essentially best fit 
reg.best10 <- regsubsets(Salary~. , data = hittersC, nvmax = 10, nbest = 1, method = "exhaustive")  

# leaps::regsubsets() - Model selection by exhaustive (default) search, forward or backward stepwise, or sequential replacement
#The plot will show the Adjust R^2 when using the variables across the bottom
plot(reg.best10, scale = "adjr2", main = "Adjusted R^2")
plot(reg.best10, scale = "r2", main = "R^2")
# In the "leaps" package, we can use scale=c("bic","Cp","adjr2","r2")
plot(reg.best10, scale = "bic", main = "BIC")
plot(reg.best10, scale = "Cp", main = "Cp")
summary(reg.best10)
```


We used `nvmax=10` and `nbest=2` as options here. As a result, you will find two 10-variable models, two 9-variable models, two 8-variable models, etc. Can you find them in the graphical output?

**In general, BIC criteria tends to favor more predictive model, with fewer regressors, while AIC favors more explanatory model with more regressors.**

Also notice how the categorical variables are being treated. Right now, such two variables each only has TWO values/levels, so we only need one coefficient for each. In general, there will be a whole lot more variables needed for more levels.


### Exhaustive search  - Non Linear Model

Let us try non-linear model as well using feature selection with exhaustive method (`nbest=1`)

```{r}
regnonlin.forward10 <- regsubsets(Salary~(AtBat+Hits+Walks+Runs+RBI)^2+League:Division, data = hittersC, nvmax = 10)  # leaps, regsubsets: Model selection by exhaustive search, forward or backward stepwise, or sequential replacement
#The plot will show the Adjust R^2 when using the variables across the bottom
plot(regnonlin.forward10, scale = "adjr2", main = "Adjusted R^2")
plot(regnonlin.forward10, scale = "bic", main = "BIC")
plot(regnonlin.forward10, scale = "Cp", main = "Cp")
summary(regnonlin.forward10)
```

We can also use forward, backward, and seqrep (sequential replacement) methods to see if our results are any different.

From <http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/>  
1. Forward selection, which starts with no predictors in the model (the null model), iteratively adds the most contributive predictors, and stops when the improvement is no longer statistically significant.  
2. Backward selection (or backward elimination), which starts with all predictors in the model (full model), iteratively removes the least contributive predictors, and stops when you have a model where all predictors are statistically significant.  
3. Sequential replacement is sort of a combination of forward and backward selections. You start with no predictors, then sequentially add the most contributive predictors (like forward selection). After adding each new variable, remove any variables that no longer provide an improvement in the model fit (like backward selection).  

### Forward Selection

The result for forward selection (with `nvmax=10` and `nbest=2`) is here. We typically do not use the regular r2 as criteria, which usually improves with number of variables and leads to overfitting.  

```{r}
reg.forward10 <- regsubsets(Salary~., data = hittersC, nvmax = 10, nbest = 1, method = "forward")
plot(reg.forward10, scale = "adjr2", main = "Adjusted R^2")
plot(reg.forward10, scale = "bic", main = "BIC")
plot(reg.forward10, scale = "Cp", main = "Cp")
# summary(reg.forward10)
```

Can we trace the steps and procedures of the selection one level at a time? Start with the 1-var model, then 2-var, then 3?

And the non-linear model:

```{r}
regnonlin.forward10 <- regsubsets(Salary~(AtBat+Hits+Walks+Runs+RBI)^2+League:Division, data = hittersC, nvmax = 10, method="forward")  # leaps, regsubsets: Model selection by exhaustive search, forward or backward stepwise, or sequential replacement
plot(regnonlin.forward10, scale = "adjr2", main = "Adjusted R^2")
plot(regnonlin.forward10, scale = "bic", main = "BIC")
plot(regnonlin.forward10, scale = "Cp", main = "Cp")
summary(regnonlin.forward10)
```


### Backward Selection

Now backwards (`nvmax=10` and `nbest=2`)

```{r}
reg.back10 <- regsubsets(Salary~., data = hittersC, method = "backward", nvmax = 10, nbest = 2)
plot(reg.back10, scale = "adjr2", main = "Adjusted R^2")
plot(reg.back10, scale = "bic", main = "BIC")
plot(reg.back10, scale = "Cp", main = "Cp")
summary(reg.back10)
```

Again, can we trace the steps and procedures one level at a time? Start with the 10-var model, then 9-var, then 3?  


And the non-linear model (`nbest=1`).

```{r}
regnonlin.back <- regsubsets(Salary~(AtBat+Hits+Walks+Runs+RBI)^2+League:Division, data = hittersC, method = "backward", nvmax = 10)
plot(regnonlin.back, scale = "adjr2", main = "Adjusted R^2")
plot(regnonlin.back, scale = "bic", main = "BIC")
plot(regnonlin.back, scale = "Cp", main = "Cp")
summary(regnonlin.back)
```

### Sequential Replacement seqrep  

Lastly we can try seqrep method.
```{r}
reg.seqrep <- regsubsets(Salary~., data = hittersC, nvmax = 10, nbest = 2 , method = "seqrep")
plot(reg.seqrep, scale = "adjr2", main = "Adjusted R^2")
plot(reg.seqrep, scale = "bic", main = "BIC")
plot(reg.seqrep, scale = "Cp", main = "Cp")
```



## `car::subsets()`

Next, let us look at the results again using a differnt presentation. Instead of plotting the reg.forward10 results from the generic `graphics::plot()` function, we will use the `car` library function `car::subsets()` to make a different plot.
The treatment is modified from an [online source here](https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html).  

### Basic plots
We need the object resulting from `regsubsets()` for more advanced plotting. So let us first re-create a result for the default plots. 

```{r}

reg2.best <- regsubsets(Salary~. , data = hittersC, nvmax = 9, nbest = 1, method = "exhaustive") 
plot(reg2.best, scale = "adjr2", main = "Adjusted R^2")
plot(reg2.best, scale = "r2", main = "R^2")
plot(reg2.best, scale = "bic", main = "BIC")
plot(reg2.best, scale = "Cp", main = "Cp")
summary(reg2.best)
```
### Alternative plots  
We can then use the function `car::subsets()` to get some more advanced/alternative plotting. Below shows that the 6-var model AB-Ht-W-Y-D-P is at or close to the highest Adjusted $R^2$.  

```{r}
loadPkg("car")

summaryRegForward = summary(reg2.best)
# Adjusted R2
car::subsets(reg2.best, statistic="adjr2", legend = FALSE, min.size = 2, main = "Adjusted R^2")
```

If we use Mallow Cp to decide on the regressors, the "stopping rule is to start with the smallest model and gradually increase number of variables, and stop when Mallow Cp is approximately (number of regressors + 1, broken line) for the first time." (from [this article](https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html)). In our case, it happened close to broken line at the 5-var model AB-Ht-W-Y-P, and the 6-var model with AB-Ht-W-Y-D-P.  

```{r}
# 
# Mallow Cp
subsets(reg2.best, statistic="cp", legend = FALSE, min.size = 5, main = "Mallow Cp")
abline(a = 1, b = 1, lty = 3)  
# a: intercept; b: slope, 
# lty: line-type (0=blank, 1=solid (default), 2=dashed, 3=dotted, 4=dotdash, 5=longdash, 6=twodash) 
#
# this output gives the list of variables and their abbreviations
```

You can now try to go back and change `nbest = 2` on (or about) line 186, and re-run the codes.  You should see more alternative results.




