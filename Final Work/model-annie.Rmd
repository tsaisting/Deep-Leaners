---
title: "IMDB Feature Film Analysis"
author: "T2 Deep Learners: Yue Li, Shuting Cai, Mrunalini Devineni, Siddharth Das"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: united
    highlight: tango
    code_folding: hide
    number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

# Introduction


```{r init, include=FALSE}
knitr::opts_chunk$set(warning = F, message = F)
options(scientific=T, digits = 3) 

library(tidyr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(ggthemes)
library(ezids)

```

# Description of the Data 

The dataset is from the Kaggle, divided into three separate CSV files. It contains 22 variables of 85,855 movies spanning from 1894 to 2020 from multiple countries. There are also 297,705 instances of cast information. The "in development" titles are not included in the files and contain missing categories of data like the short plot on the main page, awards, external reviews, parent's guide, synopsis, faqs, news, etc. Additional features such as the production company, title groups, adult titles, instant watch options like Amazon Prime or Netflix could make the analysis much broader and ideal.

```{r data_join}
movies <- read.csv('movies.csv', header=TRUE, na.strings='')

movies <- movies[,c('imdb_title_id','title','year','genre','duration','country','language','director','avg_vote','votes','budget','reviews_from_users','production_company')]
movies <- na.omit(movies)


ratings <- read.csv('ratings.csv', header=TRUE,na.strings='')
ratings <- subset(ratings[, c(1,18:25,28:35,38:43)])
ratings <- na.omit(ratings)

movie_ratings <- merge(movies, ratings, by="imdb_title_id" )

#movie_ratings <- movie_ratings[which(movie_ratings$votes > 9999),]
#movie_ratings <- movie_ratings[!(movie_ratings$year == '2020'),]
```

```{r data preprocessing}

# budget
movie_ratings$year <- as.numeric(movie_ratings$year)
model_data <- movie_ratings
str(model_data)
library(stringr)
model_data <- separate(model_data,budget, c("symbol", "budget_num"), sep=" ")
model_data$budget_num <- as.numeric(model_data$budget_num)

currency <- data.frame(symbol=unique(model_data$symbol), currency=c(1, 0.000583036, 0.172084, 1.33, 0.577554, 0.00563052, 0.11, 0.189701,0.78, 0.013,1.08, 1.13, 0.0088, 0.512426, 0.15, 0.25, 0.23,0.013, 0.71, 0.00085, 0.0280111, 1781.26, 0.13 , 0.67, 0.16, 1.13, 0.0077, 1.43447, 0.11, 0.072, 0.15, 0.00470566, 0.0031, 0.018, 0.0064, 0.020,0.18, 0.012,  0.73, 0.044, 0.0820922, 0.73, 0.064, 0.030, 	0.00331394, 0.063 , 0.0083, 0.000069, 0.047, 0.58, 0.0000109, 0.24, 0.0723039, 0.036, 	2.62906, 1.60584, 0.00025, 0.0099, 0.036, 0.000024, 0.0093, 0.0024, 0.32, 0.00000000215874, 0.32702445, 0.0012 , 0.0057, 0.15, 1.41, 0.0049, 0.32, 0.000043, 0.23, 0.0020))

model_data <- merge(model_data, currency, by='symbol')
model_data$budget_num <- model_data$budget_num * model_data$currency

## outliers
#outliers <- unique(boxplot(model_data$budget_num, plot=TRUE)$out)
#model_data <- model_data[-which(model_data$budget_num %in% outliers),]

#outliers <- unique(boxplot(model_data$votes, plot=TRUE)$out)
#model_data <- model_data[-which(model_data$votes %in% outliers),]

#outliers <- unique(boxplot(model_data$duration, plot=TRUE)$out)
#model_data <- model_data[-which(model_data$duration %in% outliers),]

#outliers <- unique(boxplot(model_data$year, plot=TRUE)$out)
#model_data <- model_data[-which(model_data$year %in% outliers),]

model_data <- model_data[!(model_data$budget_num == 0),]



# Normalization
model_data$budget_num <- log(model_data$budget_num)
model_data$votes <- log(model_data$votes)
model_data$reviews_from_users <- model_data$reviews_from_users/100


# plot budget
g <- model_data$budget_num
m <- mean(g)
std <- sqrt(var(g))
hist(g, density=20, breaks=20, prob=TRUE, 
     xlab="x-variable", ylim=c(0, 2), 
     main="normal curve over histogram of budget")
curve(dnorm(x, mean=m, sd=std), 
      col="darkblue", lwd=2, add=TRUE, yaxt="n")


# plot votes
g <- model_data$votes
m <- mean(g)
std <- sqrt(var(g))
hist(g, density=20, breaks=20, prob=TRUE, 
     xlab="x-variable", ylim=c(0, 2), 
     main="normal curve over histogram of votes")
curve(dnorm(x, mean=m, sd=std), 
      col="darkblue", lwd=2, add=TRUE, yaxt="n")

# plot reviews_from_users
g <- model_data$reviews_from_users
m <- mean(g)
std <- sqrt(var(g))
hist(g, density=20, breaks=20, prob=TRUE, 
     xlab="x-variable", ylim=c(0, 2), 
     main="normal curve over histogram of votes")
curve(dnorm(x, mean=m, sd=std), 
      col="darkblue", lwd=2, add=TRUE, yaxt="n")


```

```{r, modeling}

model_1 <- lm(avg_vote ~ budget_num+year+duration+votes+reviews_from_users, data = model_data)
summary(model_1)
```

```{r, results='markup'}
xkabledply(model_1, title = paste("Model (num):",  model_1$call$formula[2], model_1$call$formula[1], model_1$call$formula[3] ))

xkablevif(model_1)
```

```{r, results='markup'}
model_1$coefficients
model_1$call
model_1$model$final
```

```{r}
str(model_1)
str(summary(model_1))
```

```{r results='markup'}
coef(model_1)
# equivalent to
# model.final$coefficients

confint(model_1)
```


```{r}
# Using backwards elimation and the step function to find the best model with AIC highest
backward.model<- step(model_1, data=model_data, direction = "backward")
```
```{r }
#Regression Diagnostics
plot(model_1)
#Constant varaibility of residuals
plot(model_1$residuals~model_1$fitted)

#normality of residuals
qqnorm(model_1$residuals)

hist(model_1$residuals)

```

```{ }
#duration, 90min:0  90-12min:1 120min:2
model_data$duration[model_data$duration < 90] = 0
model_data$duration[model_data$duration >=90 & model_data$duration <=120 ] = 1
model_data$duration[model_data$duration > 120] = 2


### users characterizes

# genders,0:either; 1:female; 2:male; 3:both.
model_data$females_allages_vote[model_data$females_allages_vote < median(model_data$females_allages_vote)] = 0
model_data$females_allages_vote[model_data$females_allages_vote >= median(model_data$females_allages_vote)] = 1

model_data$males_allages_vote[model_data$males_allages_vote < median(model_data$males_allages_vote)] = 0
model_data$males_allages_vote[model_data$males_allages_vote >= median(model_data$males_allages_vote)] = 2

model_data$gender = model_data$females_allages_vote+ model_data$males_allages_vote


# ages, 0: neither; 1:18; 2:30,3:18+30; 4:45; 5: 18+45; 6:30+45; 7:all.
model_data$allgenders_18age_vote[model_data$allgenders_18age_vote < median(model_data$allgenders_18age_vote)] = 0
model_data$allgenders_18age_vote[model_data$allgenders_18age_vote >= median(model_data$allgenders_18age_vote)] = 1

model_data$allgenders_30age_vote[model_data$allgenders_30age_vote < median(model_data$allgenders_30age_vote)] = 0
model_data$allgenders_30age_vote[model_data$allgenders_30age_vote >= median(model_data$allgenders_30age_vote)] = 2

model_data$allgenders_45age_vote[model_data$allgenders_45age_vote < median(model_data$allgenders_45age_vote)] = 0
model_data$allgenders_45age_vote[model_data$allgenders_45age_vote >= median(model_data$allgenders_45age_vote)] = 4

model_data$age = model_data$allgenders_18age_vote+ model_data$allgenders_30age_vote+model_data$allgenders_45age_vote

# general target

model_data$avg_vote[model_data$avg_vote < median(model_data$avg_vote)] = 0
model_data$avg_vote[model_data$avg_vote >= median(model_data$avg_vote)] = 1

# factor
model_data$year <- as.factor(model_data$year)
model_data$duration <- as.factor(model_data$duration)
model_data$genre_count <- as.factor(model_data$genre_count)
model_data$director <- as.factor(model_data$director)
model_data$avg_vote <- as.factor(model_data$avg_vote)
model_data$gender <- as.factor(model_data$gender)
model_data$age <- as.factor(model_data$age)

# voting 
model_data$votes = model_data$votes/100
model_data$budget = model_data$budget/10000
model_data$worlwide_gross_income = model_data$worlwide_gross_income/10000

# budget
#model_data$budget 


model <- subset(model_data[, -c(2,7,8,14:35)])

str(model)

```

# Modeling 

# test and train data set
```{r}
data_model1 <- model[,c('avg_vote','votes','gender','age')]
library(caret)
#data(data_model1)
train <- createDataPartition(data_model1$avg_vote,p=0.7,list=FALSE)
data_train <- data_model1[train,]
data_test <- data_model1[-train,]
```


# build Logistic regression model
```{r}
lr_model <- glm(avg_vote ~ votes+gender+age,data = data_train, family = "binomial")

lr_model2 <- glm(avg_vote~ gender,data = data_train, family = "binomial")
```


```{r data}
xkabledply(lr_model)

xkabledply(lr_model2)

```

# Model Evaluation

#### Confusion matrix 
```{r confusionMatrix, results='markup'}
loadPkg("regclass")
# confusion_matrix(admitLogit)
xkabledply( confusion_matrix(lr_model), title = "Confusion matrix from Logit Model" )

xkabledply( confusion_matrix(lr_model2), title = "Confusion matrix from Logit Model" )
unloadPkg("regclass")
```

# ROC and AUC
```{r roc_auc}
loadPkg("pROC") 
prob=predict(lr_model, type = "response" )
data_train$prob=prob
h <- roc(avg_vote~prob, data=data_train)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)

prob=predict(lr_model2, type = "response" )
data_train$prob2=prob
h <- roc(avg_vote~prob2, data=data_train)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)

# unloadPkg("pROC")
```

#### McFadden  

McFadden is another evaluation tool we can use on logit regressions. This is part of what is called pseudo-R-squared values for evaluation tests. We can calculate the value directly from its definition if we so choose to.

```{r McFadden}
loadPkg("pscl") 
admitLogitpr2 = pR2(lr_model)
admitLogitpr2

admitLogitpr2_2 = pR2(lr_model2)
admitLogitpr2_2
unloadPkg("pscl") 
```


# Feature Selections on Logit Models 
First try using the package "leaps" which we learned before (for regular linear regressions). 
```{r bestglm}
data_model1 <- model[,c('age','gender','avg_vote')] 
loadPkg("bestglm")
res.bestglm <- bestglm(Xy = data_model1, family = binomial,
            IC = "AIC",                
            method = "exhaustive")
summary(res.bestglm)
res.bestglm$BestModels
summary(res.bestglm$BestModels)
unloadPkg("bestglm") 
```


# Anova test two models 
```{r data}
anova(lr_model,lr_model2)

```




# test data predict 
```{r data}
pred <- predict(lr_model2, newdata=data_test)
#confusionMatrix(data=pred,data_test$avg_vote)



```